# Machine-Learning-Evaluation-
Various ways to evaluate a machine learning model’s performance

 We will discuss the various ways to check the performance of our machine learning or deep learning model and why to use one in place of the other. We will discuss terms like:
	1. Confusion matrix
	2. Accuracy
	3. Precision
	4. Recall
	5. Specificity
	6. F1 score
	7. Precision-Recall or PR curve
	8. ROC (Receiver Operating Characteristics) curve
	9. PR vs ROC curve.

For simplicity, we will mostly discuss things in terms of a binary classification problem where let’s say we’ll have to find if an image is of a cat or a dog. Or a patient is having cancer (positive) or is found healthy (negative). Some common terms to be clear with are:
True positives (TP): Predicted positive and are actually positive.
False positives (FP): Predicted positive and are actually negative.
True negatives (TN): Predicted negative and are actually negative.
False negatives (FN): Predicted negative and are actually positive.
So let's get started!
Confusion matrix
It’s just a representation of the above parameters in a matrix format. Better visualization is always good :) 
## Please check the Uploaded PDF file
